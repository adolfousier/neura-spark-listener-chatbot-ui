services:
  neura_spark_listener:
    build:
      context: .
      dockerfile: dockerfile
    image: os_chatbot_v0.1.7
    container_name: ${CONTAINER_NAME}
    ports:
      - "${VITE_PORT}:4173"
    environment:
      # Openai service settings
      - VITE_OPENAI_API_KEY=${VITE_OPENAI_API_KEY}
      
      # Claude service settings
      - VITE_CLAUDE_API_KEY=${VITE_CLAUDE_API_KEY}

      # Optional backend with defaults
      - VITE_BACKEND_SERVICE_PROVIDER=${VITE_BACKEND_SERVICE_PROVIDER}

      # Groq service settings
      - VITE_GROQ_API_KEY=${VITE_GROQ_API_KEY}
      - VITE_GROQ_API_MODEL=${VITE_GROQ_API_MODEL}
      - VITE_STREAM_ENABLED=${VITE_STREAM_ENABLED}
      - VITE_REASONING_FORMAT=${VITE_REASONING_FORMAT}

      # Prisma service settings
      - DATABASE_URL=${DATABASE_URL}

      # Flowise service settings
      - VITE_FLOWISE_API_URL=${VITE_FLOWISE_API_URL}
      - VITE_FLOWISE_CHATFLOW_ID=${VITE_FLOWISE_CHATFLOW_ID}
      - VITE_FLOWISE_API_KEY=${VITE_FLOWISE_API_KEY}
    volumes:
      - ./public:/app/public
      #- ./prisma:/app/prisma
      #- ./prisma/dev.db:/app/prisma/dev.db
      - ./prisma/dev.db:/app/prisma/dev.db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "7"
        compress: "true"
    deploy:
      resources:
        limits:
          cpus: "0.8"
          memory: 2G
    restart: always